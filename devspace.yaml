version: v2beta1
name: vantage6git

# Import external profile configurations
imports:
  - path: dev/pipeline/profiles.yaml

# TODO using tags isnt safe with the devspace build stuff
vars:
  CURRENT_NAMESPACE:
    command: kubectl config view --minify --output 'jsonpath={..namespace}' 2>/dev/null | grep -v "^null$" | grep -v "^$" || echo "default"
  POPULATE_MARKER: ".devspace/vantage6_populate_done"
  SERVER_IMAGE: harbor2.vantage6.ai/infrastructure/server
  NODE_IMAGE: harbor2.vantage6.ai/infrastructure/node
  STORE_IMAGE: harbor2.vantage6.ai/infrastructure/algorithm-store
  UI_IMAGE: harbor2.vantage6.ai/infrastructure/ui
  NODE_PROXY_STARTING_PORT_NUMBER: 7654
  NODE_TEST_DATABASE_MOUNT_PATH:
    question: "Where is the parent folder where the node test data is located on the host machine?"
    default: ${PWD}/dev
  NODE_TEST_DATABASE_NAME:
    question: "What is the name of your node test data file?"
    default: olympic_athletes_2016.csv
  TASK_DIRECTORY:
    question: "Where is your task directory located on the host machine?"
    default: ${PWD}/dev/.tasks
  HOST_URI:
    question: "What is the ip address of your host machine?"
    default: host.docker.internal
  #set to 0.0.0.0 to make the dev environment (ui, api) accessible from outside
  PORTS_BIND_ADDRESS:
    question: "What is the bind ip address of your ports? [Bind to 'localhost' if using docker, otherwise the suggested address]"
    default: ${HOST_URI}
  NUMBER_OF_NODES:
    question: "How many nodes do you want to create for your development environment?"
    default: 3
  TASK_NAMESPACE: vantage6-tasks
  SERVER_DATABASE_MOUNT_PATH:
    question: "Where is your server database located on the host machine?"
    default: ${PWD}/dev/.db/db_pv_server
  STORE_DATABASE_MOUNT_PATH:
    question: "Where is your store database located on the host machine?"
    default: ${PWD}/dev/.db/db_pv_store
  K8S_NODE_NAME:
    question: "What is the name of the k8s node where the databases are running?"
    default: docker-desktop
  KEYCLOAK_URL:
    source: env
    default: http://vantage6-auth-keycloak.${CURRENT_NAMESPACE}.svc.cluster.local
  KEYCLOAK_PUBLIC_URL:
    source: env
    default: http://localhost:8080
  KEYCLOAK_REALM:
    source: env
    default: vantage6
  KEYCLOAK_FRONTEND_CLIENT:
    source: env
    default: public_client
  KEYCLOAK_ADMIN_CLIENT:
    source: env
    default: backend-admin-client
  KEYCLOAK_ADMIN_CLIENT_SECRET:
    source: env
    default: myadminclientsecret
  KEYCLOAK_ADMIN_USERNAME:
    source: env
    default: admin
  KEYCLOAK_ADMIN_PASSWORD:
    source: env
    default: admin
  DEVSPACE_ENV_FILE: ".devspace/.env"

pipelines:
  populate:
    run: |-
      python dev/populate.py \
        --number-of-nodes $NUMBER_OF_NODES \
        --task-directory $TASK_DIRECTORY \
        --task-namespace $TASK_NAMESPACE \
        --starting-port-number $NODE_PROXY_STARTING_PORT_NUMBER \
        --populate-marker $POPULATE_MARKER

  all-without-populate:
    run: |-
      run_pipelines \
        server \
        node \
        --sequential

  all-with-populate:
    run: |-
      run_pipelines \
        server \
        populate \
        node \
        --sequential

  server:
    run: |-
      run_dependencies --all
      ensure_pull_secrets --all
      create_deployments \
        vantage6-server \
        vantage6-store \
        vantage6-auth
      start_dev \
        vantage6-server \
        vantage6-server-db \
        vantage6-ui \
        vantage6-store \
        vantage6-store-db \
        vantage6-auth

  node:
    run: |-
      create_deployments \
        vantage6-node
      start_dev \
        vantage6-node

  purge:
    run: |-
      echo "Purging all deployments..."
      stop_dev --all
      purge_deployments --all
      run_dependencies --all --pipeline purge
      dev/purge_keycloak_storage.sh
      python dev/cleanup_task_jobs.py --namespace ${TASK_NAMESPACE}
      dev/purge_data.sh \
        ${POPULATE_MARKER} \
        ${TASK_DIRECTORY} \
        ${SERVER_DATABASE_MOUNT_PATH} \
        ${STORE_DATABASE_MOUNT_PATH}
  stop-dev:
    run: |-
      echo "Purging all deployments..."
      stop_dev --all
      purge_deployments --all
      run_dependencies --all --pipeline purge

hooks:
  # Execute the hook in a golang shell (cross operating system compatible)
  - name: "create-tasks-folder"
    command: |
      echo "Creating tasks folder"
      python dev/create_mount_directory.py ${TASK_DIRECTORY}
    events: ["before:deploy:vantage6-node"]
  - name: "create-server-database-folder"
    command: |
      echo "Creating server database folder"
      python dev/create_mount_directory.py ${SERVER_DATABASE_MOUNT_PATH}
    events: ["before:deploy:vantage6-server"]
  - name: "create-store-database-folder"
    command: |
      echo "Creating algorithm store database folder"
      python dev/create_mount_directory.py ${STORE_DATABASE_MOUNT_PATH}
    events: ["before:deploy:vantage6-store"]
  - name: "check-storage-enabled-microk8s"
    command: |
      dev/check_microk8s_storage_enabled.sh
    events: ["before:deploy:vantage6-auth"]

# This is a list of `images` that DevSpace can build for this project. These can be
# build with `devspace build` or when running `devspace dev -b`.
images:
  server:
    image: ${SERVER_IMAGE}
    dockerfile: docker/node-and-server.Dockerfile
    context: .
  node:
    image: ${NODE_IMAGE}
    dockerfile: docker/node-and-server.Dockerfile
    context: .
  store:
    image: ${STORE_IMAGE}
    dockerfile: docker/algorithm-store.Dockerfile
    context: .
  ui:
    image: "${UI_IMAGE}"
    dockerfile: docker/ui_dev.Dockerfile
    context: .

# This is a list of `deployments` that DevSpace can create for this project
# By default, image tags are automatically updated/replaced in the deployments with the
# image tags that are built by DevSpace (see `.devspace/cache.yaml`). To disable this,
# set `updateImageTags: false` in the deployment.
deployments:
  vantage6-auth:
    helm:
      chart:
        name: ./charts/auth
      values:
        service:
          type: ClusterIP
        keycloak:
          # for dev environment, we don't need TLS for internal Keycloak communication
          # as everything is on HTTP, not HTTPS
          production: false
          tls:
            enabled: false
          keycloakConfigCli:
            configuration:
              realm:
                # overwrite password policy - we don't need to enforce a password policy
                # for dev environment
                passwordPolicy: ""
                # Overwrite users: for dev environment, initialize admin user fully and
                # turn off MFA, so we don't need to configure OTP and setup account on
                # first login.
                users:
                  - username: admin
                    enabled: true
                    emailVerified: true
                    email: admin@vantage6.org
                    firstName: Admin
                    lastName: Admin
                    credentials:
                      - type: password
                        # note that for the dev env, we also overwrite the password in
                        # the values.yaml file (this pw is easier)
                        value: admin
                  - username: service-account-backend-admin-client
                    enabled: true
                    serviceAccountClientId: backend-admin-client
                    clientRoles:
                      realm-management:
                        - view-users
                        - manage-users
                        - view-clients
                        - manage-clients
                        - create-client
                # turn off TOTP / MFA in dev environment
                requiredActions:
                  - alias: CONFIGURE_TOTP
                    name: Configure OTP
                    providerId: CONFIGURE_TOTP
                    enabled: true
                    defaultAction: false

  # The server deployment contains the server, database, rabbit mq and the UI. The
  # store is deployed separately as it can have an many-to-many relationship with the
  # server (This is also why they are in separate Helm charts).
  vantage6-server:
    helm:
      chart:
        name: ./charts/server
      values:
        server:
          image: ${SERVER_IMAGE} # needed for automatic image tag update
          keycloakUrl: ${KEYCLOAK_URL}
          keycloakRealm: ${KEYCLOAK_REALM}
          keycloakAdminUsername: ${KEYCLOAK_ADMIN_USERNAME}
          keycloakAdminPassword: ${KEYCLOAK_ADMIN_PASSWORD}
          keycloakAdminClient: ${KEYCLOAK_ADMIN_CLIENT}
          keycloakAdminClientSecret: ${KEYCLOAK_ADMIN_CLIENT_SECRET}
          logging:
            level: DEBUG
          jwt:
            secret: development-constant-secret!
          dev:
            host_uri: ${HOST_URI}
            allow_drop_all: true
            store_address: http://vantage6-store-store-service.${CURRENT_NAMESPACE}.svc.cluster.local:7602
          algorithm_stores:
            - name: Local store
              url: http://vantage6-store-store-service.${CURRENT_NAMESPACE}.svc.cluster.local:7602
              api_path: /store
        ui:
          image: ${UI_IMAGE}
          keycloakPublicUrl: ${KEYCLOAK_PUBLIC_URL}
          keycloakRealm: ${KEYCLOAK_REALM}
          keycloakClient: ${KEYCLOAK_FRONTEND_CLIENT}

        database:
          volumePath: ${SERVER_DATABASE_MOUNT_PATH}
          k8sNodeName: ${K8S_NODE_NAME}

  # The store deployment contains the store and the database.
  vantage6-store:
    helm:
      chart:
        name: ./charts/store
      values:
        store:
          image: ${STORE_IMAGE}
          api_path: /store
          keycloakUrl: ${KEYCLOAK_URL}
          keycloakRealm: ${KEYCLOAK_REALM}
          keycloakAdminUsername: ${KEYCLOAK_ADMIN_USERNAME}
          keycloakAdminPassword: ${KEYCLOAK_ADMIN_PASSWORD}
          keycloakAdminClient: ${KEYCLOAK_ADMIN_CLIENT}
          keycloakAdminClientSecret: ${KEYCLOAK_ADMIN_CLIENT_SECRET}
          logging:
            level: DEBUG
          vantage6ServerUri: http://localhost:7601/server
          policies:
            allowLocalhost: true
            assignReviewOwnAlgorithm: true
          dev:
            host_uri: ${HOST_URI}
            disable_review: true
            review_own_algorithm: true

        # This is the location of the database on the host system. In case you are using
        # Windows in combination with WSL, you should put a path here that is accessible
        # by the Docker daemon. For example you can use the following path:
        #
        #   volumePath: /run/desktop/mnt/host/wsl/[SOME_PATH]
        #
        # This creates a mount to the `/mnt/wsl/[SOME_PATH]` directory. Note that this
        # directory is emptied when the WSL2 instance is restarted.
        database:
          volumePath: ${STORE_DATABASE_MOUNT_PATH}
          k8sNodeName: ${K8S_NODE_NAME}

  # The node deployment should not be 'deployed' only, it should only be deployed in
  # combination with the `dev` container (The node container that is started by the
  # `dev` section of this file). This is because the node deployment requires the
  # configuration files that are generated by the `dev` container. These are then
  # mounted into the node container. The node starts then in development mode using
  # the `dev_start.py` script. This allows us to run multiple nodes in a single
  # container. The good part about this is that all nodes receive hot-reloaded code :)
  vantage6-node:
    helm:
      chart:
        name: ./charts/node
      # See the env section in the dev section where the database environment variables
      # are set.
      values:
        node:
          image: ${NODE_IMAGE}
          numberOfNodes: ${NUMBER_OF_NODES}
          keycloakUrl: ${KEYCLOAK_URL}
          keycloakRealm: ${KEYCLOAK_REALM}
          nodeProxyStartingPortNumber: ${NODE_PROXY_STARTING_PORT_NUMBER}
          databases:
            fileBased:
              - name: default
                uri: ${NODE_TEST_DATABASE_MOUNT_PATH}/${NODE_TEST_DATABASE_NAME}
                type: csv
                volumePath: ${NODE_TEST_DATABASE_MOUNT_PATH}
                originalName: ${NODE_TEST_DATABASE_NAME}
            serviceBased: []
          k8sNodeName: ${K8S_NODE_NAME}
          persistence:
            tasks:
              hostPath: ${TASK_DIRECTORY}
          logging:
            level: DEBUG

# This is a list of `dev` containers that are based on the containers created by your deployments
dev:
  # This starts keycloak in development mode.
  vantage6-auth:
    labelSelector:
      app.kubernetes.io/instance: vantage6-auth
    ports:
      - port: 8080:8080

  # This puts the server container in development mode. It syncs the local files with
  # the container and starts the server in development mode. Code changes will be
  # hot-reloaded and a port forward is created to access the server.
  vantage6-server:
    labelSelector:
      component: vantage6-server
    sync:
      - path: ./vantage6/:/vantage6/vantage6/
        disableDownload: true
      - path: ./vantage6-common/:/vantage6/vantage6-common/
        disableDownload: true
      - path: ./vantage6-backend-common/:/vantage6/vantage6-backend-common/
        disableDownload: true
      - path: ./vantage6-server/:/vantage6/vantage6-server/
        disableDownload: true
        startContainer: true
    command: ["/bin/sh", "/vantage6/vantage6-server/dev_server.sh"]
    ports:
      - port: 7601:7601
        bindAddress: localhost
      - port: 7601:7601
        bindAddress: ${PORTS_BIND_ADDRESS}
    logs:
      enabled: true

  vantage6-server-db:
    labelSelector:
      app: vantage6-server
      component: postgres
    ports:
      # expose the server database port
      - port: 7632:5432
        bindAddress: localhost
      - port: 7632:5432
        bindAddress: ${PORTS_BIND_ADDRESS}

  vantage6-store:
    imageSelector: ${STORE_IMAGE}
    ports:
      - port: 7602:7602
        bindAddress: localhost
      - port: 7602:7602
        bindAddress: ${PORTS_BIND_ADDRESS}
    logs:
      enabled: true
    sync:
      - path: ./vantage6/:/vantage6/vantage6/
        disableDownload: true
      - path: ./vantage6-common/:/vantage6/vantage6-common/
        disableDownload: true
      - path: ./vantage6-backend-common/:/vantage6/vantage6-backend-common/
        disableDownload: true
      - path: ./vantage6-algorithm-store/:/vantage6/vantage6-algorithm-store/
        disableDownload: true
        startContainer: true
    command: ["/bin/sh", "/vantage6/vantage6-algorithm-store/dev_store.sh"]

  vantage6-store-db:
    labelSelector:
      app: store
      component: postgres
    ports:
      # expose the store database port
      - port: 7633:5432
        bindAddress: localhost
      - port: 7633:5432
        bindAddress: ${PORTS_BIND_ADDRESS}

  vantage6-ui:
    imageSelector: ${UI_IMAGE}
    command: ["/app/startup/dev_startup.sh"]
    sync:
      # Ideally we'd include the entire dir vantage6-ui/ but that leads to issues
      # with the node_modules dir, as well as with the JSON files. Changing these
      # usually requires image rebuild so it's not a big deal, but also not ideal.
      - path: ./vantage6-ui/src/:/app/src/
        disableDownload: true
      - path: ./vantage6-ui/startup/:/app/startup/
        disableDownload: true
    ports:
      - port: 7600:80
        bindAddress: localhost
      - port: 7600:80
        bindAddress: ${PORTS_BIND_ADDRESS}
    logs:
      enabled: true

  # Where as we could hot-reload the server code using wsgi, we cannot do this with the
  # node code. We leverage the `restartHelper` and `onUpload.restartContainer` to
  # restart the node container (with multiple nodes) when the code changes.
  vantage6-node:
    labelSelector:
      component: node
    env:
      - name: "DATABASE_LABELS"
        value: "default"
      - name: "DATABASE_DEFAULT_URI"
        value: ${NODE_TEST_DATABASE_MOUNT_PATH}/${NODE_TEST_DATABASE_NAME}
      - name: "DATABASE_DEFAULT_TYPE"
        value: "csv"
    sync:
      - path: ./vantage6/:/vantage6/vantage6/
        disableDownload: true
        onUpload:
          restartContainer: true
      - path: ./vantage6-common/:/vantage6/vantage6-common/
        disableDownload: true
        onUpload:
          restartContainer: true
      - path: ./vantage6-node/:/vantage6/vantage6-node/
        disableDownload: true
        onUpload:
          restartContainer: true
      # It is possible to manually add nodes. You need to put the configuration files in
      # the `dev/.data` directory. The `dev_start.py` script will then start the nodes.
      - path: ./dev/.data/:/mnt/config/
        disableDownload: true
        startContainer: true
        onUpload:
          restartContainer: true
    logs:
      enabled: true

    restartHelper:
      inject: true

    command: ["bash", "/vantage6/vantage6-node/dev_start.sh", "/mnt/config/"]

# Use the `commands` section to define repeatable dev workflows for this project
commands:
  # This will put all components in development mode. This is the main entrypoint
  # for development.
  start-dev:
    description: "Start the development environment. Use --repopulate to repopulate the server."
    command: |
      if ! command -v uname >/dev/null 2>&1; then
        echo "--------------------------------"
        echo "Error: This script must be run in a Unix-like shell (Bash/sh)."
        echo "Windows OS is not supported! Please use WSL2 if you are on Windows."
        echo "--------------------------------"
        exit 1
      fi
      POPULATE=$(./dev/ask_populate_marker.sh $POPULATE_MARKER "$@")
      $(./dev/get_start_command.sh $POPULATE $POPULATE_MARKER "$@")

  # This will remove all running k8s resources from the development mode.
  stop-dev:
    description: "Stop the development environment"
    command: devspace run-pipeline stop-dev

  # This will delete all running k8s resources and local data (e.g. tasks data, database data).
  # This is useful when you want to start from scratch.
  purge:
    description: "Purge the development environment"
    command: devspace purge

  # This will build all images for this project. This is probably the first command
  # you want to run. In case you do not run it, it will pull the latest images from
  # our harbor registry (which potentially has outdated dependencies).
  rebuild:
    description: "Rebuild images for this project (use --server, --node, --store, --ui for specific images)"
    command: |
      $(./dev/get_rebuild_command.sh "$@")
